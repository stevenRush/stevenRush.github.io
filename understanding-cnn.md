<a name='vis'></a>

## Визуализация того, чему обучается сверточная нейронная сеть

Несколько способов интерпретации и визуализации сверточных нейронных сетей были опубликованы в последнее время как ответ на распространенную критику о том, что нейронные сети с трудом поддаются интерпретации. В данной статье мы расскажем о некоторых из подходов к визуализации и дадим ссылки на другие статьи по данной тематике.

### Визуализация значений активационной функции и весов первого слоя

**Активации на различных слоях**. Самый простой способ визуализировать нейросеть - это показать активации в процессе прямого прохода. Для ReLU сетей, активации обычно сначала выглядят плотно и кучковато, но при дальнейшем обучении они становятся более разреженными и локализованными. С помощью визуализации можно заметить один из опасных подводных камней функции активации ReLU - некоторые области после активации состоят полностью из нулей, что может указывать на "мертвые" фильтры и констатирует, что скорость обучения (learning rate) слишком велика.

<div class="fig figcenter fighighlight">
  <img src="/assets/cnnvis/act1.jpeg" width="49%">
  <img src="/assets/cnnvis/act2.jpeg" width="49%">
  <div class="figcaption">
    Типичная картина активаций на первом свертночном слое (слева) и на 5 сверточном слое (справа) сети AlexNet, которая анализирует изображение кошки. Каждый квадрат показывает карту активаций, соответствующую какому-либо фильтру. Заметьте, что активации разрежены (большинство значений нули, на картинке это соответствует черному цвету) и достаточно локализированы.
  </div>
</div> <br>


**Веса сверточных/полносвязных слоев.** Второй распространенный подход - это визуализация весов нейросети. Наиболее легко интерпретировать веса первого слоя, так как он имеет дело с пикселями изображения напрямую, но также возможно визуализировать и веса более глубоких слоев. Отображение весов полезно потому, что хорошо натренированная сеть обычно имеет четкие и интерпретируемые фильтры без шума. Шумовые фильтры обычно указывают на то, что время обучения нейросети было недостаточно долгим или, возможно, что регуляризация была слишком слабой и это привело к переобучению.

<div class="fig figcenter fighighlight">
  <img src="/assets/cnnvis/filt1.jpeg" width="49%">
  <img src="/assets/cnnvis/filt2.jpeg" width="49%">
  <div class="figcaption">
    Типичное изображение фильтров первого сверточного слоя (слева) и второго сверточного слоя (справа) в полностью обученной сети AlexNet. Заметьте, что веса первого уровня выглядят четко и гладко, указывая на то, что обучение нейронной сети сошлось к довольно оптимальному решению. Цветные и черно-белые признаки кластеризованы, потому что AlexNet содержить два отдельных потока обработки изображения и очевидное следствие данной архитектуры, что один поток учится выделять частовстречаемые черно-белые признаки, а второй поток выучивает редковстречающиеся цветные признаки. Веса второго сверточного слоя не совсем интерпретируемы, но очевидно, что изображения являются четкими и гладкими, без шума.
  </div>
</div> <br>


### Поиск изображений, которые максимально активируют разные нейроны

Другим подходом к визуализации сверточной нейросети является поиск характерных изображений в большом корпусе. Для этого все изображения из набор прогоняются через нейронную сеть и отслеживаются картинки, которые максимально активируют тот или иной нейрон. Затем можно отобразить соответствующие изображения и понять, за какой шаблон отвечает данный нейрон. Пример такой визуализации можно найти в [Rich feature hierarchies for accurate object detection and semantic segmentation](http://arxiv.org/abs/1311.2524) за авторством Ross Girshick et al.:

<div class="fig figcenter fighighlight">
  <img src="/assets/cnnvis/pool5max.jpeg" width="100%">
  <div class="figcaption">
    Изображения, которые имеют наибольшие значения функции активации для некоторых нейронов в 5 сверточном слое (после пуллинга) в AlexNet. Белым указаны конкретные значения функции активации. (Кстати, заметьте, что нейроны в пуллинге 5 сверточного слоя несут сигнал с довольной большой части исходного изображения!). Также можно заметить, что некоторые нейроны отвечают за торсовую часть тела, текст или специлазированные шаблоны. 
  </div>
</div> <br>


Одной из проблем данного подхода является то, что сами ReLU нейроны не несут в себе определенного семантического значения. Напротив, лучше думать о нескольких ReLU нейронах как о базисных векторах в некотором пространстве, которое содержит кусочки изображения. Другими словами, данная визуализация показывает кусочки, которые находятся на границе некоторого многообразия представлений, в то время как координатные оси отвечают за веса, соответствующие конкретным фильтрам. Такой же вывод можно сделать из факта, что нейроны в сверточной нейросети линейно преобразуют входное пространство, поэтому любое вращение данного пространства не меняет ничего. Данный аспект был детально изучен в [Intriguing properties of neural networks](http://arxiv.org/abs/1312.6199) за автороством Szegedy et al., где авторы сделали похожую визуализацию в пространстве представлений. 

### Визуализация дескрипторов картинок с помощью t-SNE

Сверточные нейронные сети могут быть интерпретированы как пошаговая трансформация исходного изображения в векторное представление, в котором далее классы могут быть разделены линейным классификатором. Мы можем понять общую идею устройства данного пространства путем вложения его в двумерное, где итоговые двумерные представления изображений имеют примерно похожие попарные расстояния, что и в исходном пространстве. Существует много методов понижения размерности, реализующих идею сохранения попарных расстояний и наиболее популярным является [t-SNE](http://lvdmaaten.github.io/tsne/), результаты которого очень хорошо подходят для визуализации

Чтобы снизить размерность, мы берем набор изображений и используем сверточную сеть для извлечения векторных представлений (например в AlexNet это 4096-мерный вектор со слоя, прямо перед линейным классификатором, и, что наиболее важно, после применения активационной функции ReLU). Затем мы можем применить t-SNE и получить двумерный вектор для каждого изображения. И затем отобразим изображения на координатной плоскости: 

<div class="fig figcenter fighighlight">
  <img src="/assets/cnnvis/tsne.jpeg" width="100%">
  <div class="figcaption">
    t-SNE представление набора изображений, основанное на их CNN-дескрипторах. Картинки, расположенные рядом, также близки в исходном пространстве 4096-мерных дескрипторов, что означает что сверточная сеть считает их похожими. Заметьте, что близость в пространстве чаще означает совпадающий класс или похожесть по смыслу, чем основанную на похожести пикселей или цветовой палитры. Подробнее о принципе работы данной визуализации можно почитать в <a href="http://cs.stanford.edu/people/karpathy/cnnembed/">t-SNE visualization of CNN codes</a>.
  </div>
</div> <br>

### Закрашивание определенных частей изображения

Предположим, что сверточная сеть классифицирует изображение собаки. Но как мы можем быть уверены, что модель действительно распознает на картинке собаку, а не извлекает данную информацию из контекста и заднего фона? Одним способом определить, из какой части изображения нейросеть извлекает сигнал является построение графика вероятности, что на картинке изображена собака, в зависимости от позиции закрашиваемого кусочка. Мы просто можем пройтись окном по изображению, обнулять все пиксели, попавшие в окно и затем анализировать вероятность правильного решения. Это может быть изображено как двумерная тепловая карта. Данный подход был использовать в статье Matthew Zeiler [Visualizing and Understanding Convolutional Networks](http://arxiv.org/abs/1311.2901):

<div class="fig figcenter fighighlight">
  <img src="/assets/cnnvis/occlude.jpeg" width="100%">
  <div class="figcaption">
    Сверху изображены три входных картинки. Закрашиваемый кусочек показан серым цветом. В процессе перемещения закрашивающего окна по изображению, мы записывали вероятность правильного класса и затем отобразили это на тепловой карте (расположено под каждым изображением). Например, мы видим, что на самом левом изображении вероятность того, что на картинке изображен шпиц падает, когда закрашивающее окно накрывает морду собаки. Это дает нам некоторую степень уверенности в том, что морда собаки несет основной сигнал для точной классификации. Напротив, закрашивание других частей изображения не оказывает большого влияния на выход модели. 
  </div>
</div> <br>

### Визуализация градиентов

**Data Gradient**.

[Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](http://arxiv.org/abs/1312.6034)

**DeconvNet**.

[Visualizing and Understanding Convolutional Networks](http://arxiv.org/abs/1311.2901)

**Guided Backpropagation**.

[Striving for Simplicity: The All Convolutional Net](http://arxiv.org/abs/1412.6806)

### Восстановление исходных изображений из дескрипторов

[Understanding Deep Image Representations by Inverting Them](http://arxiv.org/abs/1412.0035)

### Сохраняют ли нейросети пространственную информацию?

[Do ConvNets Learn Correspondence?](http://papers.nips.cc/paper/5420-do-convnets-learn-correspondence.pdf) (короче: да)

### Построение графика качества, как функции атрибутов изображения

[ImageNet Large Scale Visual Recognition Challenge](http://arxiv.org/abs/1409.0575)

## Обман свертночных сетей

[Explaining and Harnessing Adversarial Examples](http://arxiv.org/abs/1412.6572)

## Сравнение свертночных сетей и людей-ассессоров

[What I learned from competing against a ConvNet on ImageNet](http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/)
